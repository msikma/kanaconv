KanaConv
========

**Converts hiragana and katakana to rÅmaji according to Modified Hepburn
transliteration rules.**

<p align="center">
ã¨ã†ãã‚‡ã† â†’ tÅkyÅã€€ã€€ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼ â†’ pÄtÄ«
</p>

For a full overview of the rules by which this module operates, see [the
Wikipedia page on Hepburn romanization](https://en.wikipedia
.org/wiki/Hepburn_romanization). In addition to Modified Hepburn, this module
implements a commonsense way to handle some rare and uncommon edge cases
(with some limitations; see below).

The converter attempts to produce sensible output even when given unusual
character combinations that don't normally occur in dictionary words.

Compatible with Python 2.7 and 3.4.


Installation and usage
----------------------

The easiest way to install this module is by using `pip`, e.g.:

    $ pip install kanaconv
This will allow you to use the command line utility:

```
$ kanaconv ã‚¦ã‚§ã‚¹ãƒˆ
wesuto
$ kanaconv ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒ³
sÅ«pÄman
$ kanaconv ãŒã£ã“ã†
gakkÅ
```

If you're developing an application, the converter is available
through `kanaconv.KanaConv`.

```python
from kanaconv import KanaConv
conv = KanaConv()

conv.to_romaji('ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒ³')ã€€ # u'sÅ«pÄman'
conv.to_romaji('ã“ãŠã‚Š')ã€€ã€€ã€€ã€€ # u'kÅri'
conv.to_romaji('ãŠã­ãˆã•ã‚“')ã€€ã€€ # u'onÄ“san'
conv.to_romaji('ã¨ã†ãã‚‡ã†')ã€€ã€€ # u'tÅkyÅ'
conv.to_romaji('ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼')ã€€ã€€ # u'pÄtÄ«'
conv.to_romaji('ã¬ã‚Œ|ãˆã‚“')ã€€ã€€ã€€# u'nureen' (æ¿¡ã‚Œç¸; see section on word borders)
```

Note: just use `u'ã‚«ã‚¿ã‚«ãƒŠ'` when working with Python 2.7.


Transliteration support
-----------------------

Aside from basic hiragana and katakana, the following characters are supported:

* The wi/we kana charactersï¼ˆã‚ã‚‘ãƒ»ãƒ°ãƒ±ï¼‰
* Rare characters that are mostly for loanwords (ãƒºãƒ¸ãƒ·ãƒ´ã‚”)
* The repeater charactersï¼ˆã‚ã‚ãƒ½ãƒ¾ï¼‰
* The yori and koto ligaturesï¼ˆã‚Ÿãƒ»ãƒ¿ï¼‰
* Numerous punctuation and bracket characters (e.g. ã€ã€‘ã€Œã€ãƒ»ã€‚, etc)

Conversely, the following characters and features are not supported,
with no plans to support them in the future unless they are requested
with a real-life use case:

* Half width katakana (U+FF65 - U+FF9F)
* Enclosed katakana (U+32D0 - U+32FE)
* Katakana phonetic extensions (U+31F0 - U+31FF)
* Historical kana supplement (U+1B000, U+1B001)
* "Here" sign (ğŸˆ; U+1F201)
* "Service" sign (ğŸˆ‚; U+1F202)
* "Data" sign (ğŸˆ“; U+1F213)
* Rare typographical symbols
* Vertical-only symbols

### Word borders

Generally, combinations such as *o + u* are transliterated with a macron
character, e.g. *Å*. This is not the case when there is a word border
between the two vowels.

For example, the word å­ï¼ˆã“ï¼‰é¦¬ï¼ˆã†ã¾ï¼‰has the *o + u* vowels split across
two separate words. Hence, no long vowel is pronounced, and the correct
transliteration is *kouma*.

Since the module does not have an internal dictionary, it can't know that
ã“ã†ã¾ is split across two words in such a way. In order to get a correct
transliteration, you need to manually add a pipe character to the input
to indicate the border, e.g. ã“|ã†ã¾:

```python
# transliteration of å­é¦¬
conv.to_romaji(u'ã“ã†ã¾')ã€€ã€€ã€€ã€€ # u'kÅma'  - incorrect
conv.to_romaji(u'ã“|ã†ã¾')ã€€ã€€ã€€ã€€# u'kouma' - correct
```

This rule applies to the combinations *a + a*, *u + u*, *e + e*, *o + o*,
and *o + u*. The *i + i* combination is written as *ii*, but an extended
vowel due to a long vowel marker is written as *Ä«*. All other combinations
of vowels are always written separately.

### Unicode blocks

The following full Unicode blocks are supported in this module:

**<p align="center">
Katakana Unicode Block
</p>**
<p align="center">
ã€€ã€€ã€€ã€€ã€€ã€€ã€€ï¼ã€€ï¼‘ã€€ï¼’ã€€ï¼“ã€€ï¼”ã€€ï¼•ã€€ï¼–ã€€ï¼—ã€€ï¼˜ã€€ï¼™ã€€ï¼¡ã€€ï¼¢ã€€ï¼£ã€€ï¼¤ã€€ï¼¥ã€€ï¼¦<br />
ï¼µï¼‹ï¼“ï¼ï¼¡ï½˜ã€€ã‚ ã€€ã‚¡ã€€ã‚¢ã€€ã‚£ã€€ã‚¤ã€€ã‚¥ã€€ã‚¦ã€€ã‚§ã€€ã‚¨ã€€ã‚©ã€€ã‚ªã€€ã‚«ã€€ã‚¬ã€€ã‚­ã€€ã‚®ã€€ã‚¯<br />
ï¼µï¼‹ï¼“ï¼ï¼¢ï½˜ã€€ã‚°ã€€ã‚±ã€€ã‚²ã€€ã‚³ã€€ã‚´ã€€ã‚µã€€ã‚¶ã€€ã‚·ã€€ã‚¸ã€€ã‚¹ã€€ã‚ºã€€ã‚»ã€€ã‚¼ã€€ã‚½ã€€ã‚¾ã€€ã‚¿<br />
ï¼µï¼‹ï¼“ï¼ï¼£ï½˜ã€€ãƒ€ã€€ãƒã€€ãƒ‚ã€€ãƒƒã€€ãƒ„ã€€ãƒ…ã€€ãƒ†ã€€ãƒ‡ã€€ãƒˆã€€ãƒ‰ã€€ãƒŠã€€ãƒ‹ã€€ãƒŒã€€ãƒã€€ãƒã€€ãƒ<br />
ï¼µï¼‹ï¼“ï¼ï¼¤ï½˜ã€€ãƒã€€ãƒ‘ã€€ãƒ’ã€€ãƒ“ã€€ãƒ”ã€€ãƒ•ã€€ãƒ–ã€€ãƒ—ã€€ãƒ˜ã€€ãƒ™ã€€ãƒšã€€ãƒ›ã€€ãƒœã€€ãƒã€€ãƒã€€ãƒŸ<br />
ï¼µï¼‹ï¼“ï¼ï¼¥ï½˜ã€€ãƒ ã€€ãƒ¡ã€€ãƒ¢ã€€ãƒ£ã€€ãƒ¤ã€€ãƒ¥ã€€ãƒ¦ã€€ãƒ§ã€€ãƒ¨ã€€ãƒ©ã€€ãƒªã€€ãƒ«ã€€ãƒ¬ã€€ãƒ­ã€€ãƒ®ã€€ãƒ¯<br />
ï¼µï¼‹ï¼“ï¼ï¼¦ï½˜ã€€ãƒ°ã€€ãƒ±ã€€ãƒ²ã€€ãƒ³ã€€ãƒ´ã€€ãƒµã€€ãƒ¶ã€€ãƒ·ã€€ãƒ¸ã€€ãƒ¹ã€€ãƒºã€€ãƒ»ã€€ãƒ¼ã€€ãƒ½ã€€ãƒ¾ã€€ãƒ¿<br />
</p>

**<p align="center">
Hiragana Unicode Block
</p>**
<p align="center">
ã€€ã€€ã€€ã€€ã€€ã€€ã€€ï¼ã€€ï¼‘ã€€ï¼’ã€€ï¼“ã€€ï¼”ã€€ï¼•ã€€ï¼–ã€€ï¼—ã€€ï¼˜ã€€ï¼™ã€€ï¼¡ã€€ï¼¢ã€€ï¼£ã€€ï¼¤ã€€ï¼¥ã€€ï¼¦<br />
ï¼µï¼‹ï¼“ï¼ï¼”ï½˜ã€€ã€€ã€€ãã€€ã‚ã€€ãƒã€€ã„ã€€ã…ã€€ã†ã€€ã‡ã€€ãˆã€€ã‰ã€€ãŠã€€ã‹ã€€ãŒã€€ãã€€ãã€€ã<br />
ï¼µï¼‹ï¼“ï¼ï¼•ï½˜ã€€ãã€€ã‘ã€€ã’ã€€ã“ã€€ã”ã€€ã•ã€€ã–ã€€ã—ã€€ã˜ã€€ã™ã€€ãšã€€ã›ã€€ãœã€€ãã€€ãã€€ãŸ<br />
ï¼µï¼‹ï¼“ï¼ï¼–ï½˜ã€€ã ã€€ã¡ã€€ã¢ã€€ã£ã€€ã¤ã€€ã¥ã€€ã¦ã€€ã§ã€€ã¨ã€€ã©ã€€ãªã€€ã«ã€€ã¬ã€€ã­ã€€ã®ã€€ã¯<br />
ï¼µï¼‹ï¼“ï¼ï¼—ï½˜ã€€ã°ã€€ã±ã€€ã²ã€€ã³ã€€ã´ã€€ãµã€€ã¶ã€€ã·ã€€ã¸ã€€ã¹ã€€ãºã€€ã»ã€€ã¼ã€€ã½ã€€ã¾ã€€ã¿<br />
ï¼µï¼‹ï¼“ï¼ï¼˜ï½˜ã€€ã‚€ã€€ã‚ã€€ã‚‚ã€€ã‚ƒã€€ã‚„ã€€ã‚…ã€€ã‚†ã€€ã‚‡ã€€ã‚ˆã€€ã‚‰ã€€ã‚Šã€€ã‚‹ã€€ã‚Œã€€ã‚ã€€ã‚ã€€ã‚<br />
ï¼µï¼‹ï¼“ï¼ï¼™ï½˜ã€€ã‚ã€€ã‚‘ã€€ã‚’ã€€ã‚“ã€€ã‚”ã€€ã‚•ã€€ã‚–ã€€ã€€ã€€ã€€ã€€ã‚™ã€€ã‚šã€€ã‚›ã€€ã‚œã€€ã‚ã€€ã‚ã€€ã‚Ÿ<br />
</p>

</p>

There are a number of other blocks for e.g. half-width characters and other
rare glyphs, but none of them are supported.

More info on the supported typographic symbols can be found
[on the Wikipedia page for Japanese typographic symbols](https://en.wikipedia.org/wiki/Japanese_typographic_symbols).

### Existing English terms

A lot of katakana loan words have English equivalents, but this module will
only return transliterated rÅmaji. For example, ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼ is transliterated to
"pÄtÄ«", whereas the English term is "party".

The use of an internal dictionary to handle these word replacements is
considered to be out of scope for this project. Additionally, proper names
like TÅkyÅ are not capitalized for the same reason.

### Limitations (unusual combinations and edge cases)

This module will attempt to create sensible output even in the case of
unusual character combinations that normally don't occur in a dictionary.
However, there's a limit to what we can infer from the kana alone.

A number of cases are ambiguous, or can have a different preferred
romanization based on the word. They're sufficiently rare (most of these
have practically zero usage in dictionary words) that we've settled on a
single implementation.

* ã‚¦ã‚© is transliterated as 'wo', though it can represent 'vo' in rare words
* ãƒ´ã‚£ and ãƒ¸ are transliterated as 'vi', but could also be 'wi'
* ã‚¯ãƒ® is transliterated as 'kuwa', though 'kwa' is also possible; in general,
  ãƒ® behaves exactly like ãƒ¯
* ã‚‘ and ãƒ± are technically 'we', sometimes 'ye', but are pronounced and
  transliterated as 'e'
* ã‚ is technically 'wi', but is pronounced and transliterated as 'i'
* ãƒ° can be 'i', 'wi' or 'vi' depending on the word; we've settled on 'i'
  in all cases
* ã‚– could theoretically be 'ke' in online speech, but it's the (nearly unused)
  hiragana version of ãƒ¶ which is always 'ka', so it's considered 'ka' here
  too

If these behaviors need to be changed as per a real life example, feel free
to send in a comment or a PR.


Development
-----------

I'm always glad to accept pull requests or to look at issues or questions.

### Tests

Run `./setup.py test` to run the unit tests. An additional speed test
is included as well, which you can run with
`python -m kanaconv.tests.test_speed`.


License
-------

MIT licensed.
